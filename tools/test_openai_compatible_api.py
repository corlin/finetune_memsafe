#!/usr/bin/env python3
"""
OpenAIå…¼å®¹APIå¿«é€Ÿæµ‹è¯•å·¥å…·

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•OpenAIå…¼å®¹çš„APIï¼Œ
ç±»ä¼¼äºcurlå‘½ä»¤ï¼Œä½†æä¾›äº†æ›´å‹å¥½çš„ç•Œé¢å’Œé”™è¯¯å¤„ç†ã€‚

ä½¿ç”¨ç¤ºä¾‹:
# æµ‹è¯•BigModel GLM-4.5
python tools/test_openai_compatible_api.py \
  --url "https://open.bigmodel.cn/api/paas/v4/chat/completions" \
  --token "your_api_key" \
  --model "glm-4.5" \
  --message "ä¸­å›½å¤§æ¨¡å‹è¡Œä¸šåœ¨2025å¹´å°†é¢ä¸´å“ªäº›æœºé‡å’ŒæŒ‘æˆ˜ï¼Ÿ"

# æµ‹è¯•DeepSeek
python tools/test_openai_compatible_api.py \
  --url "https://api.deepseek.com/v1/chat/completions" \
  --token "your_api_key" \
  --model "deepseek-chat" \
  --message "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"

# ä»æ–‡ä»¶è¯»å–æ¶ˆæ¯
python tools/test_openai_compatible_api.py \
  --url "https://api.openai.com/v1/chat/completions" \
  --token "your_api_key" \
  --model "gpt-3.5-turbo" \
  --message-file "test_message.txt"
"""

import sys
import os
import argparse
import json
import time
import requests
from typing import Dict, Any, Optional


def send_chat_request(url: str, token: str, model: str, message: str,
                     system_prompt: Optional[str] = None,
                     max_tokens: int = 1000,
                     temperature: float = 0.7,
                     timeout: int = 30,
                     custom_headers: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
    """
    å‘é€èŠå¤©è¯·æ±‚åˆ°OpenAIå…¼å®¹API
    
    Args:
        url: APIç«¯ç‚¹URL
        token: APIä»¤ç‰Œ
        model: æ¨¡å‹åç§°
        message: ç”¨æˆ·æ¶ˆæ¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        max_tokens: æœ€å¤§ä»¤ç‰Œæ•°
        temperature: æ¸©åº¦å‚æ•°
        timeout: è¶…æ—¶æ—¶é—´
        custom_headers: è‡ªå®šä¹‰è¯·æ±‚å¤´
        
    Returns:
        Dict[str, Any]: APIå“åº”ç»“æœ
    """
    # æ„å»ºè¯·æ±‚å¤´
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    if custom_headers:
        headers.update(custom_headers)
    
    # æ„å»ºæ¶ˆæ¯
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": message})
    
    # æ„å»ºè¯·æ±‚æ•°æ®
    data = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature
    }
    
    try:
        print(f"ğŸš€ å‘é€è¯·æ±‚åˆ°: {url}")
        print(f"ğŸ“ æ¨¡å‹: {model}")
        print(f"ğŸ’¬ æ¶ˆæ¯: {message[:100]}{'...' if len(message) > 100 else ''}")
        print(f"âš™ï¸  å‚æ•°: max_tokens={max_tokens}, temperature={temperature}")
        if system_prompt:
            print(f"ğŸ¯ ç³»ç»Ÿæç¤º: {system_prompt[:50]}{'...' if len(system_prompt) > 50 else ''}")
        print()
        
        start_time = time.time()
        
        response = requests.post(
            url,
            headers=headers,
            json=data,
            timeout=timeout
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        print(f"â±ï¸  å“åº”æ—¶é—´: {response_time:.2f}ç§’")
        print(f"ğŸ“Š çŠ¶æ€ç : {response.status_code}")
        
        # å¤„ç†å“åº”
        if response.status_code == 200:
            result = response.json()
            
            # æå–å›å¤å†…å®¹
            if "choices" in result and result["choices"]:
                content = result["choices"][0].get("message", {}).get("content", "")
                usage = result.get("usage", {})
                
                print("âœ… è¯·æ±‚æˆåŠŸ!")
                print(f"ğŸ“„ å›å¤å†…å®¹:")
                print("-" * 50)
                print(content)
                print("-" * 50)
                
                if usage:
                    print(f"ğŸ“ˆ ä»¤ç‰Œä½¿ç”¨: è¾“å…¥={usage.get('prompt_tokens', 'N/A')}, "
                          f"è¾“å‡º={usage.get('completion_tokens', 'N/A')}, "
                          f"æ€»è®¡={usage.get('total_tokens', 'N/A')}")
                
                return {
                    "success": True,
                    "content": content,
                    "response_time": response_time,
                    "usage": usage,
                    "raw_response": result
                }
            else:
                print("âŒ å“åº”æ ¼å¼å¼‚å¸¸: ç¼ºå°‘choiceså­—æ®µ")
                return {
                    "success": False,
                    "error": "å“åº”æ ¼å¼å¼‚å¸¸",
                    "raw_response": result
                }
        else:
            # å¤„ç†é”™è¯¯å“åº”
            try:
                error_data = response.json()
                error_message = error_data.get("error", {}).get("message", "æœªçŸ¥é”™è¯¯")
            except:
                error_message = response.text or f"HTTP {response.status_code}"
            
            print(f"âŒ è¯·æ±‚å¤±è´¥: {error_message}")
            
            return {
                "success": False,
                "error": error_message,
                "status_code": response.status_code,
                "response_time": response_time
            }
            
    except requests.exceptions.Timeout:
        print(f"â° è¯·æ±‚è¶…æ—¶ ({timeout}ç§’)")
        return {"success": False, "error": "è¯·æ±‚è¶…æ—¶"}
    
    except requests.exceptions.ConnectionError as e:
        print(f"ğŸ”Œ è¿æ¥é”™è¯¯: {str(e)}")
        return {"success": False, "error": f"è¿æ¥é”™è¯¯: {str(e)}"}
    
    except requests.exceptions.RequestException as e:
        print(f"ğŸ“¡ è¯·æ±‚é”™è¯¯: {str(e)}")
        return {"success": False, "error": f"è¯·æ±‚é”™è¯¯: {str(e)}"}
    
    except json.JSONDecodeError as e:
        print(f"ğŸ“‹ JSONè§£æé”™è¯¯: {str(e)}")
        return {"success": False, "error": f"JSONè§£æé”™è¯¯: {str(e)}"}
    
    except Exception as e:
        print(f"ğŸ’¥ æœªçŸ¥é”™è¯¯: {str(e)}")
        return {"success": False, "error": f"æœªçŸ¥é”™è¯¯: {str(e)}"}


def load_message_from_file(file_path: str) -> str:
    """ä»æ–‡ä»¶åŠ è½½æ¶ˆæ¯å†…å®¹"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    except Exception as e:
        raise ValueError(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="OpenAIå…¼å®¹APIå¿«é€Ÿæµ‹è¯•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

# æµ‹è¯•BigModel GLM-4.5
python tools/test_openai_compatible_api.py \\
  --url "https://open.bigmodel.cn/api/paas/v4/chat/completions" \\
  --token "your_api_key" \\
  --model "glm-4.5" \\
  --message "ä¸­å›½å¤§æ¨¡å‹è¡Œä¸šåœ¨2025å¹´å°†é¢ä¸´å“ªäº›æœºé‡å’ŒæŒ‘æˆ˜ï¼Ÿ"

# æµ‹è¯•DeepSeek
python tools/test_openai_compatible_api.py \\
  --url "https://api.deepseek.com/v1/chat/completions" \\
  --token "your_api_key" \\
  --model "deepseek-chat" \\
  --message "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"

# ä½¿ç”¨ç³»ç»Ÿæç¤ºè¯
python tools/test_openai_compatible_api.py \\
  --url "https://api.openai.com/v1/chat/completions" \\
  --token "your_api_key" \\
  --model "gpt-3.5-turbo" \\
  --message "è§£é‡Šé‡å­è®¡ç®—" \\
  --system "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘å­¦è§£é‡Šå‘˜ï¼Œè¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µã€‚"
        """
    )
    
    parser.add_argument("--url", required=True, help="APIç«¯ç‚¹URL")
    parser.add_argument("--token", required=True, help="APIä»¤ç‰Œ")
    parser.add_argument("--model", required=True, help="æ¨¡å‹åç§°")
    
    # æ¶ˆæ¯è¾“å…¥æ–¹å¼ï¼ˆäºŒé€‰ä¸€ï¼‰
    message_group = parser.add_mutually_exclusive_group(required=True)
    message_group.add_argument("--message", help="ç”¨æˆ·æ¶ˆæ¯å†…å®¹")
    message_group.add_argument("--message-file", help="ä»æ–‡ä»¶è¯»å–æ¶ˆæ¯å†…å®¹")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--system", help="ç³»ç»Ÿæç¤ºè¯")
    parser.add_argument("--max-tokens", type=int, default=1000, help="æœ€å¤§ä»¤ç‰Œæ•° (é»˜è®¤: 1000)")
    parser.add_argument("--temperature", type=float, default=0.7, help="æ¸©åº¦å‚æ•° (é»˜è®¤: 0.7)")
    parser.add_argument("--timeout", type=int, default=30, help="è¶…æ—¶æ—¶é—´ç§’æ•° (é»˜è®¤: 30)")
    parser.add_argument("--header", action="append", help="è‡ªå®šä¹‰è¯·æ±‚å¤´ï¼Œæ ¼å¼: Key:Value")
    parser.add_argument("--output", "-o", help="ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶")
    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
    
    args = parser.parse_args()
    
    print("OpenAIå…¼å®¹APIæµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    try:
        # è·å–æ¶ˆæ¯å†…å®¹
        if args.message:
            message = args.message
        else:
            message = load_message_from_file(args.message_file)
        
        # è§£æè‡ªå®šä¹‰è¯·æ±‚å¤´
        custom_headers = {}
        if args.header:
            for header in args.header:
                if ":" not in header:
                    print(f"âŒ æ— æ•ˆçš„è¯·æ±‚å¤´æ ¼å¼: {header} (åº”ä¸º Key:Value)")
                    return 1
                key, value = header.split(":", 1)
                custom_headers[key.strip()] = value.strip()
        
        # å‘é€è¯·æ±‚
        result = send_chat_request(
            url=args.url,
            token=args.token,
            model=args.model,
            message=message,
            system_prompt=args.system,
            max_tokens=args.max_tokens,
            temperature=args.temperature,
            timeout=args.timeout,
            custom_headers=custom_headers if custom_headers else None
        )
        
        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        if args.verbose:
            print("\nğŸ” è¯¦ç»†ä¿¡æ¯:")
            print(json.dumps(result, ensure_ascii=False, indent=2))
        
        # ä¿å­˜ç»“æœ
        if args.output:
            try:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
            except Exception as e:
                print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
        
        # è¿”å›é€€å‡ºç 
        return 0 if result.get("success", False) else 1
        
    except Exception as e:
        print(f"ğŸ’¥ ç¨‹åºé”™è¯¯: {str(e)}")
        return 1


if __name__ == "__main__":
    exit(main())