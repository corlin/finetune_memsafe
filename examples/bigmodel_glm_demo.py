#!/usr/bin/env python3
"""
BigModel GLM API æ¼”ç¤ºç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨industry_evaluationç³»ç»Ÿæµ‹è¯•BigModelçš„GLMç³»åˆ—æ¨¡å‹ï¼Œ
åŒ…æ‹¬GLM-4.5ç­‰æ¨¡å‹çš„APIè°ƒç”¨å’Œè¯„ä¼°ã€‚

ä½¿ç”¨æ–¹æ³•:
1. è®¾ç½®ç¯å¢ƒå˜é‡: export BIGMODEL_API_KEY="your_api_key_here"
2. è¿è¡Œç¤ºä¾‹: python examples/bigmodel_glm_demo.py

æˆ–è€…ç›´æ¥ä¼ é€’APIå¯†é’¥:
python examples/bigmodel_glm_demo.py --api-key your_api_key_here
"""

import sys
import os
import argparse
import json
import time
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from industry_evaluation.adapters.model_adapter import ModelAdapterFactory, ModelManager
from industry_evaluation.core.interfaces import EvaluationConfig


def create_bigmodel_test_dataset() -> List[Dict[str, Any]]:
    """åˆ›å»ºé’ˆå¯¹BigModel GLMçš„æµ‹è¯•æ•°æ®é›†"""
    return [
        {
            "id": "glm_test_1",
            "input": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿè¯·ç®€è¦ä»‹ç»å…¶å‘å±•å†ç¨‹å’Œä¸»è¦åº”ç”¨é¢†åŸŸã€‚",
            "expected_output": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
            "context": {
                "domain": "technology",
                "difficulty": "basic",
                "max_tokens": 500,
                "temperature": 0.7
            }
        },
        {
            "id": "glm_test_2",
            "input": "ä¸­å›½å¤§æ¨¡å‹è¡Œä¸šåœ¨2025å¹´å°†é¢ä¸´å“ªäº›æœºé‡å’ŒæŒ‘æˆ˜ï¼Ÿè¯·ä»æŠ€æœ¯ã€å¸‚åœºã€æ”¿ç­–ç­‰è§’åº¦åˆ†æã€‚",
            "expected_output": "2025å¹´ä¸­å›½å¤§æ¨¡å‹è¡Œä¸šå°†é¢ä¸´å¤šé‡æœºé‡å’ŒæŒ‘æˆ˜ã€‚æœºé‡æ–¹é¢åŒ…æ‹¬æŠ€æœ¯åˆ›æ–°åŠ é€Ÿã€åº”ç”¨åœºæ™¯æ‰©å±•ã€äº§ä¸šæ•°å­—åŒ–éœ€æ±‚å¢é•¿ç­‰ã€‚",
            "context": {
                "domain": "industry_analysis",
                "difficulty": "advanced",
                "max_tokens": 800,
                "temperature": 0.6,
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡Œä¸šåˆ†æå¸ˆï¼Œè¯·æä¾›æ·±å…¥ã€å®¢è§‚çš„åˆ†æã€‚"
            }
        },
        {
            "id": "glm_test_3",
            "input": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯Transformeræ¶æ„ï¼Œä»¥åŠå®ƒåœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­çš„é‡è¦ä½œç”¨ã€‚",
            "expected_output": "Transformeræ˜¯ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œç”±Googleåœ¨2017å¹´æå‡ºã€‚",
            "context": {
                "domain": "machine_learning",
                "difficulty": "intermediate",
                "max_tokens": 600,
                "temperature": 0.5
            }
        },
        {
            "id": "glm_test_4",
            "input": "å¦‚ä½•è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨æ•ˆæœï¼Ÿéœ€è¦è€ƒè™‘å“ªäº›å…³é”®æŒ‡æ ‡ï¼Ÿ",
            "expected_output": "è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨æ•ˆæœéœ€è¦è€ƒè™‘å¤šä¸ªç»´åº¦çš„æŒ‡æ ‡ã€‚",
            "context": {
                "domain": "finance",
                "difficulty": "advanced",
                "max_tokens": 700,
                "temperature": 0.4,
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªé‡‘èç§‘æŠ€ä¸“å®¶ï¼Œè¯·æä¾›ä¸“ä¸šçš„è¯„ä¼°å»ºè®®ã€‚"
            }
        },
        {
            "id": "glm_test_5",
            "input": "è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ä¸­çš„è¿‡æ‹Ÿåˆç°è±¡ï¼Œå¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚",
            "expected_output": "è¿‡æ‹Ÿåˆæ˜¯æŒ‡æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨æ–°æ•°æ®ä¸Šæ³›åŒ–èƒ½åŠ›å·®çš„ç°è±¡ã€‚",
            "context": {
                "domain": "education",
                "difficulty": "intermediate",
                "max_tokens": 500,
                "temperature": 0.8,
                "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæ•™è‚²ä¸“å®¶ï¼Œè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šå¤æ‚æ¦‚å¿µã€‚"
            }
        }
    ]


def test_bigmodel_glm_api(api_key: str, model_name: str = "glm-4.5", verbose: bool = False) -> Dict[str, Any]:
    """
    æµ‹è¯•BigModel GLM API
    
    Args:
        api_key: BigModel APIå¯†é’¥
        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºglm-4.5
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
    Returns:
        Dict[str, Any]: æµ‹è¯•ç»“æœ
    """
    print(f"\nğŸš€ å¼€å§‹æµ‹è¯• BigModel {model_name} API")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
        model_manager = ModelManager()
        
        # åˆ›å»ºBigModel GLMé€‚é…å™¨
        adapter = ModelAdapterFactory.create_openai_compatible_adapter(
            model_id=f"bigmodel_{model_name.replace('-', '_')}",
            provider="bigmodel",
            api_key=api_key,
            model_name=model_name,
            timeout=60,  # å¢åŠ è¶…æ—¶æ—¶é—´
            custom_headers={
                "User-Agent": "Industry-Evaluation-Demo/1.0"
            }
        )
        
        # æ³¨å†Œæ¨¡å‹
        model_manager.register_model(
            f"bigmodel_{model_name.replace('-', '_')}",
            "openai_compatible",
            adapter.config
        )
        
        print(f"âœ… æˆåŠŸåˆ›å»º {model_name} é€‚é…å™¨")
        print(f"ğŸ“¡ APIç«¯ç‚¹: {adapter.base_url}")
        print(f"ğŸ”‘ è®¤è¯æ–¹å¼: {adapter.auth_type}")
        
        # å¥åº·æ£€æŸ¥
        print(f"\nğŸ” æ‰§è¡Œå¥åº·æ£€æŸ¥...")
        health_status = adapter.get_health_status()
        print(f"å¥åº·çŠ¶æ€: {'âœ… å¥åº·' if health_status['is_healthy'] else 'âŒ ä¸å¥åº·'}")
        
        # å¿«é€Ÿè¿é€šæ€§æµ‹è¯•
        print(f"\nâš¡ æ‰§è¡Œå¿«é€Ÿè¿é€šæ€§æµ‹è¯•...")
        try:
            quick_test = adapter.predict("ä½ å¥½", {"max_tokens": 10})
            print(f"âœ… è¿é€šæ€§æµ‹è¯•æˆåŠŸ: {quick_test[:50]}...")
        except Exception as e:
            print(f"âŒ è¿é€šæ€§æµ‹è¯•å¤±è´¥: {str(e)}")
            return {"success": False, "error": f"è¿é€šæ€§æµ‹è¯•å¤±è´¥: {str(e)}"}
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        test_dataset = create_bigmodel_test_dataset()
        
        # æµ‹è¯•ç»“æœç»Ÿè®¡
        results = {
            "model_name": model_name,
            "provider": "bigmodel",
            "api_endpoint": adapter.base_url,
            "tests": [],
            "summary": {
                "total_tests": len(test_dataset),
                "successful_tests": 0,
                "failed_tests": 0,
                "total_response_time": 0.0,
                "average_response_time": 0.0,
                "total_tokens_used": 0
            }
        }
        
        print(f"\nğŸ“‹ å¼€å§‹æ‰§è¡Œ {len(test_dataset)} ä¸ªæµ‹è¯•ç”¨ä¾‹...")
        
        for i, sample in enumerate(test_dataset, 1):
            print(f"\n--- æµ‹è¯•ç”¨ä¾‹ {i}/{len(test_dataset)}: {sample['id']} ---")
            print(f"ğŸ“ é¢†åŸŸ: {sample['context'].get('domain', 'general')}")
            print(f"ğŸ¯ éš¾åº¦: {sample['context'].get('difficulty', 'normal')}")
            print(f"â“ é—®é¢˜: {sample['input'][:100]}{'...' if len(sample['input']) > 100 else ''}")
            
            test_result = {
                "sample_id": sample["id"],
                "domain": sample['context'].get('domain', 'general'),
                "difficulty": sample['context'].get('difficulty', 'normal'),
                "input": sample["input"],
                "success": False,
                "response": "",
                "response_time": 0.0,
                "tokens_used": 0,
                "error": None
            }
            
            try:
                start_time = time.time()
                
                # è°ƒç”¨æ¨¡å‹
                response = adapter.predict(sample["input"], sample["context"])
                
                end_time = time.time()
                response_time = end_time - start_time
                
                # ä¼°ç®—tokenä½¿ç”¨é‡ï¼ˆç®€å•ä¼°ç®—ï¼‰
                estimated_tokens = len(sample["input"]) // 4 + len(response) // 4
                
                test_result.update({
                    "success": True,
                    "response": response,
                    "response_time": response_time,
                    "tokens_used": estimated_tokens
                })
                
                results["summary"]["successful_tests"] += 1
                results["summary"]["total_response_time"] += response_time
                results["summary"]["total_tokens_used"] += estimated_tokens
                
                print(f"âœ… æˆåŠŸ (è€—æ—¶: {response_time:.2f}s, çº¦{estimated_tokens}tokens)")
                
                if verbose:
                    print(f"ğŸ“„ å›å¤å†…å®¹:")
                    print("-" * 40)
                    print(response[:300] + ("..." if len(response) > 300 else ""))
                    print("-" * 40)
                else:
                    print(f"ğŸ“„ å›å¤é¢„è§ˆ: {response[:100]}{'...' if len(response) > 100 else ''}")
                
            except Exception as e:
                test_result.update({
                    "success": False,
                    "error": str(e)
                })
                
                results["summary"]["failed_tests"] += 1
                print(f"âŒ å¤±è´¥: {str(e)}")
            
            results["tests"].append(test_result)
            
            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            if i < len(test_dataset):
                print("â³ ç­‰å¾…1ç§’é¿å…é¢‘ç‡é™åˆ¶...")
                time.sleep(1)
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        if results["summary"]["successful_tests"] > 0:
            results["summary"]["average_response_time"] = (
                results["summary"]["total_response_time"] / results["summary"]["successful_tests"]
            )
        
        # æ‰“å°æµ‹è¯•æ€»ç»“
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        print(f"ğŸ¯ æ¨¡å‹: BigModel {model_name}")
        print(f"ğŸ“ˆ æ€»æµ‹è¯•æ•°: {results['summary']['total_tests']}")
        print(f"âœ… æˆåŠŸ: {results['summary']['successful_tests']}")
        print(f"âŒ å¤±è´¥: {results['summary']['failed_tests']}")
        print(f"ğŸ“Š æˆåŠŸç‡: {results['summary']['successful_tests']/results['summary']['total_tests']*100:.1f}%")
        
        if results["summary"]["average_response_time"] > 0:
            print(f"â±ï¸  å¹³å‡å“åº”æ—¶é—´: {results['summary']['average_response_time']:.2f}s")
        
        if results["summary"]["total_tokens_used"] > 0:
            print(f"ğŸ”¢ æ€»Tokenä½¿ç”¨é‡: ~{results['summary']['total_tokens_used']}")
        
        # æŒ‰é¢†åŸŸç»Ÿè®¡
        domain_stats = {}
        for test in results["tests"]:
            domain = test["domain"]
            if domain not in domain_stats:
                domain_stats[domain] = {"total": 0, "success": 0}
            domain_stats[domain]["total"] += 1
            if test["success"]:
                domain_stats[domain]["success"] += 1
        
        print(f"\nğŸ“‹ æŒ‰é¢†åŸŸç»Ÿè®¡:")
        for domain, stats in domain_stats.items():
            success_rate = stats["success"] / stats["total"] * 100
            print(f"  {domain}: {stats['success']}/{stats['total']} ({success_rate:.1f}%)")
        
        results["domain_stats"] = domain_stats
        results["success"] = True
        
        return results
        
    except Exception as e:
        print(f"ğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "model_name": model_name,
            "provider": "bigmodel"
        }


def demonstrate_curl_equivalent(api_key: str, model_name: str = "glm-4.5"):
    """æ¼”ç¤ºç­‰æ•ˆçš„curlå‘½ä»¤"""
    print(f"\nğŸ”§ ç­‰æ•ˆçš„curlå‘½ä»¤:")
    print("=" * 60)
    
    curl_command = f'''curl --request POST \\
  --url https://open.bigmodel.cn/api/paas/v4/chat/completions \\
  --header 'Authorization: Bearer {api_key}' \\
  --header 'Content-Type: application/json' \\
  --data '{{
    "model": "{model_name}",
    "messages": [
      {{
        "role": "user",
        "content": "ä¸­å›½å¤§æ¨¡å‹è¡Œä¸šåœ¨2025å¹´å°†é¢ä¸´å“ªäº›æœºé‡å’ŒæŒ‘æˆ˜ï¼Ÿ"
      }}
    ],
    "max_tokens": 1000,
    "temperature": 0.7
  }}'
'''
    
    print(curl_command)
    print("\nğŸ’¡ ä½¿ç”¨industry_evaluationç³»ç»Ÿçš„ä¼˜åŠ¿:")
    print("  âœ… è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†")
    print("  âœ… ç»Ÿä¸€çš„æ¥å£é€‚é…å¤šä¸ªæä¾›å•†")
    print("  âœ… å†…ç½®çš„è¯„ä¼°å’Œåˆ†æåŠŸèƒ½")
    print("  âœ… æ‰¹é‡æµ‹è¯•å’Œæ€§èƒ½ç»Ÿè®¡")
    print("  âœ… é…ç½®ç®¡ç†å’Œç¯å¢ƒå˜é‡æ”¯æŒ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="BigModel GLM API æ¼”ç¤º")
    parser.add_argument("--api-key", help="BigModel APIå¯†é’¥ (ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡BIGMODEL_API_KEYè®¾ç½®)")
    parser.add_argument("--model", default="glm-4.5", help="æ¨¡å‹åç§° (é»˜è®¤: glm-4.5)")
    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†è¾“å‡º")
    parser.add_argument("--output", "-o", help="ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶")
    parser.add_argument("--show-curl", action="store_true", help="æ˜¾ç¤ºç­‰æ•ˆçš„curlå‘½ä»¤")
    
    args = parser.parse_args()
    
    # è·å–APIå¯†é’¥
    api_key = args.api_key or os.getenv("BIGMODEL_API_KEY")
    
    if not api_key:
        print("âŒ é”™è¯¯: æœªæä¾›APIå¯†é’¥")
        print("è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æä¾›APIå¯†é’¥:")
        print("  1. å‘½ä»¤è¡Œå‚æ•°: --api-key your_api_key_here")
        print("  2. ç¯å¢ƒå˜é‡: export BIGMODEL_API_KEY=your_api_key_here")
        print("\nğŸ’¡ è·å–APIå¯†é’¥:")
        print("  è®¿é—® https://open.bigmodel.cn æ³¨å†Œè´¦å·å¹¶è·å–APIå¯†é’¥")
        return 1
    
    print("BigModel GLM API æ¼”ç¤º")
    print("=" * 60)
    print(f"ğŸ¯ ç›®æ ‡æ¨¡å‹: {args.model}")
    print(f"ğŸ”‘ APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
    
    # æ˜¾ç¤ºcurlå‘½ä»¤ç¤ºä¾‹
    if args.show_curl:
        demonstrate_curl_equivalent(api_key, args.model)
        print()
    
    # æ‰§è¡Œæµ‹è¯•
    results = test_bigmodel_glm_api(
        api_key=api_key,
        model_name=args.model,
        verbose=args.verbose
    )
    
    # ä¿å­˜ç»“æœ
    if args.output:
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
    
    # æä¾›åç»­å»ºè®®
    if results.get("success", False):
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼åç»­å»ºè®®:")
        print("  ğŸ“Š æŸ¥çœ‹è¯¦ç»†ç»“æœæ–‡ä»¶äº†è§£æ›´å¤šä¿¡æ¯")
        print("  ğŸ”§ è°ƒæ•´temperatureå’Œmax_tokenså‚æ•°ä¼˜åŒ–è¾“å‡º")
        print("  ğŸ“ˆ é›†æˆåˆ°å®Œæ•´çš„è¯„ä¼°æµç¨‹ä¸­è¿›è¡Œæ·±åº¦åˆ†æ")
        print("  ğŸ”„ å®šæœŸè¿è¡Œæµ‹è¯•ç›‘æ§æ¨¡å‹æ€§èƒ½")
    
    # è¿”å›é€€å‡ºç 
    return 0 if results.get("success", False) else 1


if __name__ == "__main__":
    exit(main())