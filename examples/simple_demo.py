"""
Industry Evaluation System ç®€åŒ–æ¼”ç¤º - æ™ºè°±æ¨¡å‹ç‰ˆæœ¬

è¿™ä¸ªç¤ºä¾‹ç¨‹åºå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ™ºè°±æ¨¡å‹ï¼ˆBigModel GLMï¼‰è¿›è¡Œè¡Œä¸šè¯„ä¼°ç³»ç»Ÿçš„æ¼”ç¤ºï¼Œ
é€‚åˆå¿«é€Ÿäº†è§£ç³»ç»Ÿä¸æ™ºè°±æ¨¡å‹çš„é›†æˆä½¿ç”¨æ–¹æ³•ã€‚

ä½¿ç”¨æ–¹æ³•:
1. è®¾ç½®ç¯å¢ƒå˜é‡: export BIGMODEL_API_KEY="your_api_key_here"
2. è¿è¡Œç¤ºä¾‹: python examples/simple_demo.py

æˆ–è€…åœ¨ä»£ç ä¸­ç›´æ¥è®¾ç½®APIå¯†é’¥ï¼ˆä¸æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
"""

import json
import logging
import tempfile
import time
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# å¯¼å…¥ç³»ç»Ÿç»„ä»¶
from industry_evaluation.config.config_manager import ConfigManager, ConfigTemplate, ModelConfig
from industry_evaluation.adapters.model_adapter import ModelManager, ModelAdapterFactory
from industry_evaluation.core.evaluation_engine import IndustryEvaluationEngine
from industry_evaluation.core.result_aggregator import ResultAggregator
from industry_evaluation.reporting.report_generator import ReportGenerator
from industry_evaluation.evaluators.knowledge_evaluator import KnowledgeEvaluator
from industry_evaluation.evaluators.terminology_evaluator import TerminologyEvaluator
from industry_evaluation.core.interfaces import EvaluationConfig


def simple_evaluation_demo():
    """ä½¿ç”¨æ™ºè°±æ¨¡å‹çš„ç®€åŒ–è¯„ä¼°æ¼”ç¤º"""
    
    print("ğŸš€ Industry Evaluation System - æ™ºè°±æ¨¡å‹æ¼”ç¤º")
    print("=" * 50)
    
    # è·å–æ™ºè°±APIå¯†é’¥
    api_key = os.getenv("BIGMODEL_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æ™ºè°±APIå¯†é’¥")
        print("è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®APIå¯†é’¥:")
        print("  1. ç¯å¢ƒå˜é‡: export BIGMODEL_API_KEY=your_api_key_here")
        print("  2. æˆ–åœ¨ä»£ç ä¸­ç›´æ¥è®¾ç½® (ä¸æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ)")
        print("\nğŸ’¡ è·å–APIå¯†é’¥:")
        print("  è®¿é—® https://open.bigmodel.cn æ³¨å†Œè´¦å·å¹¶è·å–APIå¯†é’¥")
        return
    
    print(f"ğŸ”‘ APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
    
    # 1. è®¾ç½®ä¸´æ—¶ç¯å¢ƒ
    temp_dir = Path(tempfile.mkdtemp())
    config_file = temp_dir / "simple_config.yaml"
    
    print(f"ğŸ“ ä¸´æ—¶ç›®å½•: {temp_dir}")
    
    try:
        # 2. åˆ›å»ºé…ç½®
        print("\nğŸ”§ è®¾ç½®é…ç½®...")
        config = ConfigTemplate.generate_finance_config()
        ConfigTemplate.save_template(config, config_file)
        config_manager = ConfigManager(config_file, auto_reload=False)
        print("âœ… é…ç½®åˆ›å»ºå®Œæˆ")
        
        # 3. è®¾ç½®æ™ºè°±æ¨¡å‹
        print("\nğŸ¤– è®¾ç½®æ™ºè°±æ¨¡å‹...")
        model_manager = ModelManager()
        
        # åˆ›å»ºæ™ºè°±GLM-4.5æ¨¡å‹é€‚é…å™¨
        try:
            glm_adapter = ModelAdapterFactory.create_openai_compatible_adapter(
                model_id="myglm-4.5",
                provider="bigmodel",
                api_key=api_key,
                model_name="glm-4.5",
                timeout=60,
                custom_headers={
                    "User-Agent": "Industry-Evaluation-Demo/1.0"
                }
            )
            
            # æ³¨å†Œæ™ºè°±æ¨¡å‹
            model_manager.register_model(
                "glm-4.5",
                "openai_compatible",
                glm_adapter.config
            )
            
            print("âœ… æ™ºè°±GLM-4.5æ¨¡å‹è®¾ç½®å®Œæˆ")
            print(f"ğŸ“¡ APIç«¯ç‚¹: {glm_adapter.base_url}")
            
            # å¿«é€Ÿè¿é€šæ€§æµ‹è¯•
            print("ğŸ” æ‰§è¡Œè¿é€šæ€§æµ‹è¯•...")
            try:
                test_response = glm_adapter.predict("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚", {"max_tokens": 50})
                if test_response:
                    print(f"âœ… è¿é€šæ€§æµ‹è¯•æˆåŠŸ: {test_response[:100]}...")
                else:
                    print("âš ï¸ è¿é€šæ€§æµ‹è¯•è¿”å›ç©ºç»“æœï¼Œä½†è¿æ¥æ­£å¸¸")
            except Exception as test_error:
                print(f"âš ï¸ è¿é€šæ€§æµ‹è¯•å¤±è´¥: {str(test_error)}")
                print("ç»§ç»­å°è¯•è¯„ä¼°...")
            
        except Exception as e:
            print(f"âŒ æ™ºè°±æ¨¡å‹è®¾ç½®å¤±è´¥: {str(e)}")
            print("è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            return
        
        # 4. è®¾ç½®è¯„ä¼°å™¨
        print("\nğŸ“Š è®¾ç½®è¯„ä¼°å™¨...")
        evaluators = {
            "knowledge": KnowledgeEvaluator(),
            "terminology": TerminologyEvaluator()
        }
        print("âœ… è¯„ä¼°å™¨è®¾ç½®å®Œæˆ")
        
        # 5. åˆ›å»ºè¯„ä¼°å¼•æ“
        print("\nğŸš€ åˆ›å»ºè¯„ä¼°å¼•æ“...")
        result_aggregator = ResultAggregator()
        report_generator = ReportGenerator()
        
        evaluation_engine = IndustryEvaluationEngine(
            model_manager=model_manager,
            evaluators=evaluators,
            result_aggregator=result_aggregator,
            report_generator=report_generator,
            max_workers=1
        )
        print("âœ… è¯„ä¼°å¼•æ“åˆ›å»ºå®Œæˆ")
        
        # 6. å‡†å¤‡æµ‹è¯•æ•°æ®
        print("\nğŸ“ å‡†å¤‡æµ‹è¯•æ•°æ®...")
        test_dataset = [
            {
                "id": "zhipu_test_1",
                "input": "ä»€ä¹ˆæ˜¯é‡‘èé£é™©ç®¡ç†ï¼Ÿè¯·è¯¦ç»†è§£é‡Šå…¶æ ¸å¿ƒæ¦‚å¿µå’Œä¸»è¦æ–¹æ³•ã€‚",
                "expected_output": "é‡‘èé£é™©ç®¡ç†æ˜¯è¯†åˆ«ã€è¯„ä¼°å’Œæ§åˆ¶é‡‘èé£é™©çš„è¿‡ç¨‹ã€‚",
                "context": {
                    "industry": "finance", 
                    "topic": "risk_management",
                    "max_tokens": 500,
                    "temperature": 0.7,
                    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èé£é™©ç®¡ç†ä¸“å®¶ï¼Œè¯·æä¾›å‡†ç¡®ã€ä¸“ä¸šçš„å›ç­”ã€‚"
                }
            },
            {
                "id": "zhipu_test_2", 
                "input": "è¯·è§£é‡ŠVaRæ¨¡å‹çš„åŸç†ã€è®¡ç®—æ–¹æ³•å’Œåœ¨é£é™©ç®¡ç†ä¸­çš„åº”ç”¨ã€‚",
                "expected_output": "VaRï¼ˆValue at Riskï¼‰æ˜¯ä¸€ç§é£é™©åº¦é‡æ–¹æ³•ã€‚",
                "context": {
                    "industry": "finance", 
                    "topic": "risk_models",
                    "max_tokens": 600,
                    "temperature": 0.6,
                    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªé‡åŒ–é‡‘èä¸“å®¶ï¼Œè¯·è¯¦ç»†è§£é‡ŠVaRæ¨¡å‹çš„æŠ€æœ¯ç»†èŠ‚ã€‚"
                }
            },
            {
                "id": "zhipu_test_3",
                "input": "ä¸­å›½é‡‘èç§‘æŠ€è¡Œä¸šçš„å‘å±•è¶‹åŠ¿å’Œç›‘ç®¡æ”¿ç­–æœ‰å“ªäº›ï¼Ÿ",
                "expected_output": "ä¸­å›½é‡‘èç§‘æŠ€è¡Œä¸šæ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œç›‘ç®¡æ”¿ç­–ä¹Ÿåœ¨ä¸æ–­å®Œå–„ã€‚",
                "context": {
                    "industry": "fintech",
                    "topic": "industry_analysis",
                    "max_tokens": 700,
                    "temperature": 0.5,
                    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªé‡‘èç§‘æŠ€è¡Œä¸šåˆ†æå¸ˆï¼Œè¯·æä¾›å®¢è§‚ã€å…¨é¢çš„åˆ†æã€‚"
                }
            }
        ]
        print(f"âœ… å‡†å¤‡äº† {len(test_dataset)} ä¸ªæ™ºè°±æ¨¡å‹æµ‹è¯•æ ·æœ¬")
        
        # 7. æ‰§è¡Œè¯„ä¼°
        print("\nğŸ¯ å¼€å§‹è¯„ä¼°...")
        
        eval_config = EvaluationConfig(
            industry_domain="finance",
            evaluation_dimensions=["knowledge", "terminology"],
            weight_config={"knowledge": 0.7, "terminology": 0.3},
            threshold_config={"knowledge": 0.6, "terminology": 0.5}
        )
        
        # è¯„ä¼°æ™ºè°±GLM-4.5æ¨¡å‹
        print("ğŸ”„ è¯„ä¼°æ™ºè°±GLM-4.5æ¨¡å‹...")
        zhipu_task_id = evaluation_engine.evaluate_model(
            model_id="glm-4.5",
            dataset=test_dataset,
            evaluation_config=eval_config
        )
        
        # ç­‰å¾…è¯„ä¼°å®Œæˆ
        wait_for_completion(evaluation_engine, zhipu_task_id, "æ™ºè°±GLM-4.5")
        zhipu_result = evaluation_engine.get_evaluation_result(zhipu_task_id)
        
        # 8. æ˜¾ç¤ºç»“æœ
        print("\nğŸ“Š æ™ºè°±GLM-4.5è¯„ä¼°ç»“æœ:")
        print("-" * 60)
        print(f"{'æŒ‡æ ‡':<15} {'å¾—åˆ†':<10} {'è¯¦æƒ…':<35}")
        print("-" * 60)
        
        if zhipu_result:
            print(f"{'ç»¼åˆå¾—åˆ†':<15} {zhipu_result.overall_score:<10.3f} {'æ•´ä½“è¡¨ç°è¯„ä¼°':<35}")
            print(f"{'çŸ¥è¯†å‡†ç¡®æ€§':<15} {zhipu_result.dimension_scores.get('knowledge', 0):<10.3f} {'ä¸“ä¸šçŸ¥è¯†æŒæ¡ç¨‹åº¦':<35}")
            print(f"{'æœ¯è¯­ä½¿ç”¨':<15} {zhipu_result.dimension_scores.get('terminology', 0):<10.3f} {'ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å‡†ç¡®æ€§':<35}")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„æµ‹è¯•ç»“æœ
            print(f"\nğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:")
            for i, sample in enumerate(test_dataset, 1):
                print(f"\n--- æµ‹è¯•æ ·æœ¬ {i}: {sample['id']} ---")
                print(f"ğŸ“ é—®é¢˜: {sample['input'][:80]}{'...' if len(sample['input']) > 80 else ''}")
                print(f"ğŸ¯ é¢†åŸŸ: {sample['context'].get('industry', 'general')}")
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œå¦‚æœè¯„ä¼°ç»“æœåŒ…å«å•ä¸ªæ ·æœ¬çš„è¯¦æƒ…
        else:
            print("âŒ æœªè·å–åˆ°æ™ºè°±æ¨¡å‹è¯„ä¼°ç»“æœ")
        
        print("-" * 60)
        
        # 9. ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“„ ç”Ÿæˆæ™ºè°±æ¨¡å‹è¯„ä¼°æŠ¥å‘Š...")
        if zhipu_result:
            report = evaluation_engine.generate_report(zhipu_task_id, "json")
            if report:
                report_file = temp_dir / "zhipu_evaluation_report.json"
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(report if isinstance(report, str) else json.dumps(report, ensure_ascii=False, indent=2))
                print(f"âœ… æ™ºè°±æ¨¡å‹è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # 10. æ˜¾ç¤ºæ€»ç»“
        print("\nğŸ‰ æ™ºè°±æ¨¡å‹æ¼”ç¤ºå®Œæˆ!")
        print("=" * 60)
        print("âœ… å·²æ¼”ç¤ºçš„åŠŸèƒ½:")
        print("  â€¢ æ™ºè°±GLM-4.5æ¨¡å‹é›†æˆ")
        print("  â€¢ OpenAIå…¼å®¹APIé€‚é…å™¨")
        print("  â€¢ é‡‘èé¢†åŸŸä¸“ä¸šè¯„ä¼°")
        print("  â€¢ çŸ¥è¯†å‡†ç¡®æ€§è¯„ä¼°")
        print("  â€¢ æœ¯è¯­ä½¿ç”¨è¯„ä¼°")
        print("  â€¢ è¯¦ç»†æŠ¥å‘Šç”Ÿæˆ")
        print(f"\nğŸ“ æŸ¥çœ‹è¯¦ç»†ç»“æœ: {temp_dir}")
        print(f"\nğŸ’¡ åç»­å»ºè®®:")
        print("  ğŸ”§ è°ƒæ•´temperatureå’Œmax_tokenså‚æ•°ä¼˜åŒ–è¾“å‡º")
        print("  ğŸ“Š æ·»åŠ æ›´å¤šè¯„ä¼°ç»´åº¦è¿›è¡Œæ·±åº¦åˆ†æ")
        print("  ğŸ”„ å®šæœŸè¿è¡Œæµ‹è¯•ç›‘æ§æ¨¡å‹æ€§èƒ½")
        print("  ğŸ“ˆ é›†æˆåˆ°å®Œæ•´çš„è¯„ä¼°æµç¨‹ä¸­")
        
    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise
    
    finally:
        # æ¸…ç†èµ„æº
        try:
            evaluation_engine.shutdown()
        except:
            pass


def wait_for_completion(evaluation_engine, task_id, model_name):
    """ç­‰å¾…è¯„ä¼°å®Œæˆ"""
    max_wait = 120  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œå› ä¸ºAPIè°ƒç”¨å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
    start_time = time.time()
    
    print(f"â³ ç­‰å¾…{model_name}è¯„ä¼°å®Œæˆ...")
    
    while time.time() - start_time < max_wait:
        progress = evaluation_engine.get_evaluation_progress(task_id)
        
        if progress:
            if progress.status == "completed":
                print(f"âœ… {model_name}è¯„ä¼°å®Œæˆ")
                return
            elif progress.status == "failed":
                print(f"âŒ {model_name}è¯„ä¼°å¤±è´¥")
                if hasattr(progress, 'error_message'):
                    print(f"   é”™è¯¯ä¿¡æ¯: {progress.error_message}")
                return
            elif progress.status == "running":
                elapsed = time.time() - start_time
                print(f"ğŸ”„ {model_name}è¯„ä¼°è¿›è¡Œä¸­... (å·²ç”¨æ—¶: {elapsed:.1f}s)")
        
        time.sleep(2)  # å¢åŠ æ£€æŸ¥é—´éš”
    
    print(f"â° {model_name}è¯„ä¼°è¶…æ—¶ (è¶…è¿‡{max_wait}ç§’)")


def set_api_key_if_needed():
    """å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰APIå¯†é’¥ï¼Œæä¾›è®¾ç½®é€‰é¡¹"""
    if not os.getenv("BIGMODEL_API_KEY"):
        print("ğŸ”‘ æœªæ£€æµ‹åˆ°æ™ºè°±APIå¯†é’¥ç¯å¢ƒå˜é‡")
        print("è¯·é€‰æ‹©è®¾ç½®æ–¹å¼:")
        print("1. è®¾ç½®ç¯å¢ƒå˜é‡ (æ¨è): export BIGMODEL_API_KEY=your_api_key_here")
        print("2. åœ¨æ­¤å¤„ä¸´æ—¶è®¾ç½® (ä»…ç”¨äºæ¼”ç¤º)")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2): ").strip()
        
        if choice == "2":
            api_key = input("è¯·è¾“å…¥æ‚¨çš„æ™ºè°±APIå¯†é’¥: ").strip()
            if api_key:
                os.environ["BIGMODEL_API_KEY"] = api_key
                print("âœ… APIå¯†é’¥å·²ä¸´æ—¶è®¾ç½®")
            else:
                print("âŒ æœªè¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥")
                return False
        elif choice == "1":
            print("è¯·åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: export BIGMODEL_API_KEY=your_api_key_here")
            print("ç„¶åé‡æ–°è¿è¡Œæ­¤ç¨‹åº")
            return False
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return False
    
    return True


if __name__ == "__main__":
    print("ğŸš€ æ™ºè°±æ¨¡å‹æ¼”ç¤ºç¨‹åºå¯åŠ¨")
    print("=" * 60)
    
    # æ£€æŸ¥å¹¶è®¾ç½®APIå¯†é’¥
    if set_api_key_if_needed():
        simple_evaluation_demo()
    else:
        print("\nğŸ’¡ è·å–æ™ºè°±APIå¯†é’¥:")
        print("  1. è®¿é—® https://open.bigmodel.cn")
        print("  2. æ³¨å†Œè´¦å·å¹¶è·å–APIå¯†é’¥")
        print("  3. è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨ç¨‹åºä¸­è¾“å…¥å¯†é’¥")