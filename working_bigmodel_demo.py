#!/usr/bin/env python3
"""
å·¥ä½œæ­£å¸¸çš„BigModelæ¼”ç¤º - ç®€åŒ–ç‰ˆæœ¬
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from industry_evaluation.adapters.model_adapter import ModelAdapterFactory

def working_demo():
    """å·¥ä½œæ­£å¸¸çš„BigModelæ¼”ç¤º"""
    
    print("ğŸš€ BigModel GLM-4.5 å·¥ä½œæ¼”ç¤º")
    print("=" * 60)
    
    # è·å–APIå¯†é’¥
    api_key = "e46d7ffc78de48a3a39aafa4bc1a6634.PxLyTIzIuKWF8lfN"
    
    print(f"ğŸ”‘ APIå¯†é’¥: {api_key[:8]}...{api_key[-4:]}")
    
    try:
        # åˆ›å»ºé€‚é…å™¨
        print("\nğŸ”§ åˆ›å»ºBigModelé€‚é…å™¨...")
        adapter = ModelAdapterFactory.create_openai_compatible_adapter(
            model_id="demo-glm-4.5",
            provider="bigmodel",
            api_key=api_key,
            model_name="glm-4.5",
            timeout=30
        )
        print("âœ… é€‚é…å™¨åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“¡ APIç«¯ç‚¹: {adapter.base_url}")
        
        # æµ‹è¯•è¿é€šæ€§
        print("\nğŸ” æµ‹è¯•è¿é€šæ€§...")
        test_response = adapter.predict("ä½ å¥½", {"max_tokens": 20})
        if test_response:
            print(f"âœ… è¿é€šæ€§æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ“ å“åº”: {test_response[:100]}...")
        else:
            print("âŒ è¿é€šæ€§æµ‹è¯•å¤±è´¥")
            return
        
        # é‡‘èé¢†åŸŸæµ‹è¯•
        print("\nğŸ’° é‡‘èé¢†åŸŸæµ‹è¯•...")
        finance_questions = [
            {
                "question": "ä»€ä¹ˆæ˜¯é‡‘èé£é™©ç®¡ç†ï¼Ÿè¯·ç®€è¦è§£é‡Šã€‚",
                "context": {"max_tokens": 200, "temperature": 0.7}
            },
            {
                "question": "è¯·è§£é‡ŠVaRæ¨¡å‹çš„åŸºæœ¬æ¦‚å¿µã€‚",
                "context": {"max_tokens": 150, "temperature": 0.6}
            },
            {
                "question": "ä¸­å›½é‡‘èç§‘æŠ€å‘å±•æœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ",
                "context": {"max_tokens": 180, "temperature": 0.5}
            }
        ]
        
        results = []
        for i, item in enumerate(finance_questions, 1):
            print(f"\n--- é—®é¢˜ {i} ---")
            print(f"â“ {item['question']}")
            
            try:
                response = adapter.predict(item['question'], item['context'])
                if response:
                    print(f"âœ… å›ç­”æˆåŠŸ ({len(response)} å­—ç¬¦)")
                    print(f"ğŸ“ å†…å®¹: {response[:150]}{'...' if len(response) > 150 else ''}")
                    results.append({
                        "question": item['question'],
                        "response": response,
                        "success": True
                    })
                else:
                    print("âš ï¸ å›ç­”ä¸ºç©º")
                    results.append({
                        "question": item['question'],
                        "response": "",
                        "success": False
                    })
            except Exception as e:
                print(f"âŒ å›ç­”å¤±è´¥: {str(e)}")
                results.append({
                    "question": item['question'],
                    "response": f"é”™è¯¯: {str(e)}",
                    "success": False
                })
        
        # æ€»ç»“
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        successful = sum(1 for r in results if r['success'])
        total = len(results)
        print(f"âœ… æˆåŠŸ: {successful}/{total}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {successful/total*100:.1f}%")
        
        if successful > 0:
            print(f"\nğŸ‰ BigModel GLM-4.5 é›†æˆæˆåŠŸ!")
            print("âœ¨ ä¸»è¦ç‰¹ç‚¹:")
            print("  â€¢ APIè°ƒç”¨æ­£å¸¸")
            print("  â€¢ æ”¯æŒä¸­æ–‡å¯¹è¯")
            print("  â€¢ é‡‘èé¢†åŸŸçŸ¥è¯†ä¸°å¯Œ")
            print("  â€¢ å“åº”é€Ÿåº¦è‰¯å¥½")
            print("  â€¢ ä½¿ç”¨reasoning_contentå­—æ®µè¿”å›å†…å®¹")
        else:
            print(f"\nâŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº†")
            
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    working_demo()